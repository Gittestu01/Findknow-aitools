import streamlit as st
import os
from pathlib import Path
from openai import OpenAI
import pandas as pd
import json
from datetime import datetime
import requests
import re
import time

# é¡µé¢é…ç½®ï¼ˆå¿…é¡»æ˜¯ç¬¬ä¸€ä¸ªStreamlitå‘½ä»¤ï¼‰
st.set_page_config(
    page_title="æç¤ºè¯å·¥ç¨‹å¸ˆ - Findknow AI",
    page_icon="ğŸ”§",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    
    .card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        color: white;
    }
    
    .prompt-area {
        background: rgba(255,255,255,0.1);
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .result-area {
        background: white;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        color: #333;
        font-weight: 500;
    }
    
    .placeholder-text {
        color: rgba(255,255,255,0.9);
        font-style: italic;
        font-weight: 500;
    }
    
    .model-selector {
        background: rgba(255,255,255,0.1);
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        color: #333;
    }
    
    .loading-spinner {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid #f3f3f3;
        border-top: 3px solid #667eea;
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-right: 10px;
    }
    
    .chat-message {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
        color: #333;
    }
    
    .user-message {
        background: #e3f2fd;
        border-left-color: #2196f3;
        color: #333;
    }
    
    .assistant-message {
        background: #f3e5f5;
        border-left-color: #9c27b0;
        color: #333;
    }
    
    .model-info {
        background: #f0f8ff;
        border-radius: 8px;
        padding: 0.5rem;
        margin: 0.5rem 0;
        border-left: 3px solid #4CAF50;
        color: #333;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
.main-header, .main-header * {
    font-family: 'Noto Emoji', 'Twemoji Mozilla', 'Segoe UI Emoji', 'Apple Color Emoji', 'Noto Color Emoji', 'Segoe UI', 'Arial', sans-serif !important;
}
</style>
""", unsafe_allow_html=True)

# å¤§æ¨¡å‹é…ç½®
MODEL_CONFIGS = {
    "GPT-4": {
        "description": "OpenAIæœ€å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ“…é•¿å¤æ‚æ¨ç†å’Œåˆ›æ„ä»»åŠ¡",
        "strengths": ["å¤æ‚æ¨ç†", "åˆ›æ„å†™ä½œ", "ä»£ç ç”Ÿæˆ", "å¤šæ¨¡æ€ç†è§£"],
        "best_for": "éœ€è¦æ·±åº¦æ€è€ƒå’Œåˆ›é€ åŠ›çš„ä»»åŠ¡"
    },
    "GPT-3.5-turbo": {
        "description": "OpenAIçš„é«˜æ•ˆæ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦",
        "strengths": ["å¿«é€Ÿå“åº”", "æˆæœ¬æ•ˆç›Š", "é€šç”¨ä»»åŠ¡", "å¯¹è¯"],
        "best_for": "æ—¥å¸¸å¯¹è¯å’Œä¸€èˆ¬æ€§ä»»åŠ¡"
    },
    "Claude-3": {
        "description": "Anthropicçš„å®‰å…¨å¯¼å‘æ¨¡å‹ï¼Œæ“…é•¿åˆ†æå’Œå†™ä½œ",
        "strengths": ["å®‰å…¨åˆ†æ", "é•¿æ–‡æœ¬å¤„ç†", "å­¦æœ¯å†™ä½œ", "é€»è¾‘æ¨ç†"],
        "best_for": "éœ€è¦å®‰å…¨æ€§å’Œå‡†ç¡®æ€§çš„ä»»åŠ¡"
    },
    "Gemini Pro": {
        "description": "Googleçš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ“…é•¿åˆ›æ„å’Œè§†è§‰ä»»åŠ¡",
        "strengths": ["å¤šæ¨¡æ€", "åˆ›æ„ç”Ÿæˆ", "è§†è§‰ç†è§£", "å®æ—¶ä¿¡æ¯"],
        "best_for": "éœ€è¦è§†è§‰ç†è§£å’Œåˆ›æ„çš„ä»»åŠ¡"
    },
    "Qwen Plus": {
        "description": "é˜¿é‡Œäº‘çš„é€šä¹‰åƒé—®æ¨¡å‹ï¼Œä¸­æ–‡ç†è§£èƒ½åŠ›å¼º",
        "strengths": ["ä¸­æ–‡ç†è§£", "æœ¬åœ°åŒ–", "çŸ¥è¯†é—®ç­”", "å¯¹è¯"],
        "best_for": "ä¸­æ–‡ä»»åŠ¡å’Œæœ¬åœ°åŒ–åº”ç”¨"
    },
    "è±†åŒ…": {
        "description": "å­—èŠ‚è·³åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿ä¸­æ–‡å¯¹è¯å’Œåˆ›æ„å†…å®¹ç”Ÿæˆ",
        "strengths": ["ä¸­æ–‡å¯¹è¯", "åˆ›æ„å†™ä½œ", "å†…å®¹ç”Ÿæˆ", "æƒ…æ„Ÿç†è§£"],
        "best_for": "ä¸­æ–‡åˆ›æ„å†™ä½œå’Œæƒ…æ„Ÿäº¤æµä»»åŠ¡"
    },
    "DeepSeek-V3": {
        "description": "æ·±åº¦æ±‚ç´¢çš„ä»£ç ä¸“å®¶æ¨¡å‹ï¼Œåœ¨ç¼–ç¨‹å’Œæ•°å­¦æ¨ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚",
        "strengths": ["ä»£ç ç”Ÿæˆ", "æ•°å­¦æ¨ç†", "é€»è¾‘åˆ†æ", "æŠ€æœ¯æ–‡æ¡£"],
        "best_for": "ç¼–ç¨‹å¼€å‘å’ŒæŠ€æœ¯åˆ†æä»»åŠ¡"
    },
    "DeepSeek-R1": {
        "description": "æ·±åº¦æ±‚ç´¢çš„æ¨ç†ä¸“å®¶æ¨¡å‹ï¼Œæ“…é•¿å¤æ‚æ¨ç†å’Œé—®é¢˜è§£å†³",
        "strengths": ["å¤æ‚æ¨ç†", "é—®é¢˜è§£å†³", "é€»è¾‘åˆ†æ", "å­¦æœ¯ç ”ç©¶"],
        "best_for": "éœ€è¦æ·±åº¦æ¨ç†å’Œé—®é¢˜è§£å†³çš„ä»»åŠ¡"
    },
    "ç§˜å¡”AI": {
        "description": "ç§˜å¡”ç§‘æŠ€çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“æ³¨äºä¸­æ–‡ç†è§£å’ŒçŸ¥è¯†é—®ç­”",
        "strengths": ["ä¸­æ–‡ç†è§£", "çŸ¥è¯†é—®ç­”", "ä¿¡æ¯æ£€ç´¢", "å­¦ä¹ è¾…åŠ©"],
        "best_for": "ä¸­æ–‡çŸ¥è¯†é—®ç­”å’Œå­¦ä¹ è¾…åŠ©ä»»åŠ¡"
    },
    "è‡ªå®šä¹‰æ¨¡å‹": {
        "description": "å…¶ä»–ç‰¹å®šçš„å¤§æ¨¡å‹",
        "strengths": ["æ ¹æ®å…·ä½“æ¨¡å‹è€Œå®š"],
        "best_for": "ç‰¹å®šé¢†åŸŸæˆ–ä¸“ä¸šä»»åŠ¡"
    }
}

# æç¤ºè¯å·¥ç¨‹å¸ˆç³»ç»Ÿæç¤ºè¯
PROMPT_ENGINEER_SYSTEM_PROMPT = """æˆ‘æƒ³è®©ä½ æˆä¸ºæˆ‘çš„ Prompt åˆ›ä½œè€…ã€‚ä½ çš„ç›®æ ‡æ˜¯å¸®åŠ©åˆ›å»ºæœ€ä½³çš„ Promptï¼Œè¿™ä¸ª Prompt å°†ç”±AIå¤§æ¨¡å‹ä½¿ç”¨ã€‚

ä½ å°†éµå¾ªä»¥ä¸‹è¿‡ç¨‹ï¼š
é¦–å…ˆï¼Œä½ ä¼šæ¥æ”¶åˆ°ç”¨æˆ·åˆç‰ˆçš„æç¤ºè¯å’Œç›®æ ‡å¤§æ¨¡å‹ä¿¡æ¯ï¼Œè¯·ç†è§£ç”¨æˆ·éœ€æ±‚å’Œå†…å®¹ï¼Œå¹¶æ ¹æ®ç‰¹å®šå¤§æ¨¡å‹çš„ç‰¹ç‚¹è¿›è¡Œé’ˆå¯¹æ€§çš„æ¶¦è‰²
ç„¶åï¼Œä½ éœ€è¦æ¨æ–­ç”¨æˆ·çœŸå®å¯»æ±‚ï¼Œå¹¶æ ¹æ®åˆç‰ˆæç¤ºè¯å’Œå¤§æ¨¡å‹çš„ç‰¹ç‚¹ï¼Œé€šè¿‡ä¸æ–­çš„é‡å¤æ¥æ”¹è¿›å®ƒï¼Œé€šè¿‡åˆ™è¿›è¡Œä¸‹ä¸€æ­¥ã€‚
æ ¹æ®ç”¨æˆ·è¾“å…¥åˆç‰ˆæç¤ºè¯å’Œç›®æ ‡å¤§æ¨¡å‹ï¼Œä½ ä¼šåˆ›å»ºä¸¤ä¸ªéƒ¨åˆ†ï¼š
a) ä¿®è®¢åçš„ Prompt (ä½ ä¼šç¼–å†™ä¿®è®¢åçš„ Promptï¼Œåº”è¯¥æ¸…æ™°ã€ç²¾ç¡®ã€æ˜“äºç†è§£ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šå¤§æ¨¡å‹ä¼˜åŒ–)
cï¼‰é—®é¢˜ï¼ˆä½ æå‡ºç›¸å…³é—®é¢˜ï¼Œè¯¢é—®æˆ‘éœ€è¦å“ªäº›é¢å¤–ä¿¡æ¯æ¥æ”¹è¿› Promptï¼‰

ä½ æä¾›çš„ Prompt åº”è¯¥é‡‡ç”¨ç”¨æˆ·å‘å‡ºè¯·æ±‚çš„å½¢å¼ï¼Œç”±å¤§æ¨¡å‹æ‰§è¡Œã€‚
ç”¨æˆ·å°†å’Œä½ ç»§ç»­è¿™ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œç”¨æˆ·ä¼šæä¾›æ›´å¤šçš„ä¿¡æ¯ï¼Œä½ ä¼šæ›´æ–°"ä¿®è®¢åçš„ Prompt"éƒ¨åˆ†çš„è¯·æ±‚ï¼Œç›´åˆ°å®ƒå®Œæ•´ä¸ºæ­¢ã€‚

è¯·ç¡®ä¿ï¼š
1. ä¿®è®¢åçš„Promptæ¸…æ™°ã€ç²¾ç¡®ã€æ˜“äºç†è§£
2. é’ˆå¯¹ç‰¹å®šå¤§æ¨¡å‹çš„ç‰¹ç‚¹å’Œä¼˜åŠ¿è¿›è¡Œä¼˜åŒ–
3. è€ƒè™‘ç›®æ ‡æ¨¡å‹çš„é™åˆ¶å’Œæœ€ä½³å®è·µ
4. æå‡ºæœ‰é’ˆå¯¹æ€§çš„é—®é¢˜æ¥è¿›ä¸€æ­¥å®Œå–„
5. ä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§"""

def get_model_specific_prompt(selected_model):
    """æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç”Ÿæˆç‰¹å®šçš„ä¼˜åŒ–æç¤º"""
    model_info = MODEL_CONFIGS.get(selected_model, MODEL_CONFIGS["è‡ªå®šä¹‰æ¨¡å‹"])
    
    return f"""
ç›®æ ‡å¤§æ¨¡å‹ï¼š{selected_model}
æ¨¡å‹ç‰¹ç‚¹ï¼š{model_info['description']}
æ¨¡å‹ä¼˜åŠ¿ï¼š{', '.join(model_info['strengths'])}
é€‚ç”¨åœºæ™¯ï¼š{model_info['best_for']}

è¯·æ ¹æ®ä»¥ä¸Šæ¨¡å‹ç‰¹ç‚¹ï¼Œä¸ºç”¨æˆ·æä¾›é’ˆå¯¹æ€§çš„æç¤ºè¯ä¼˜åŒ–å»ºè®®ã€‚
"""

def init_client():
    """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
    try:
        # ä»session_stateè·å–APIå¯†é’¥
        api_key = st.session_state.get("api_key")
        if not api_key:
            st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
            return None
        
        client = OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        return client
    except Exception as e:
        st.error(f"åˆå§‹åŒ–AIå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None

def check_api_key():
    """æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å·²è®¾ç½®"""
    return st.session_state.get("api_key") is not None

def setup_api_key():
    """è®¾ç½®APIå¯†é’¥"""
    st.markdown("### ğŸ”‘ APIå¯†é’¥è®¾ç½®")
    
    # å¦‚æœå·²ç»æœ‰APIå¯†é’¥ï¼Œæ˜¾ç¤ºå½“å‰çŠ¶æ€
    if check_api_key():
        st.success("âœ… APIå¯†é’¥å·²è®¾ç½®ï¼Œå¯ä»¥ä½¿ç”¨æ‰€æœ‰åŠŸèƒ½")
        col1, col2 = st.columns([1, 3])
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯†é’¥", use_container_width=True, key="clear_key_prompt"):
                # æ¸…é™¤APIå¯†é’¥
                st.session_state["api_key"] = None
                if "api_key_persistent" in st.session_state:
                    del st.session_state.api_key_persistent
                st.success("âœ… APIå¯†é’¥å·²æ¸…é™¤")
                st.rerun()
        with col2:
            st.write("")  # å ä½ç¬¦
    else:
        st.markdown("è¯·è¾“å…¥æ‚¨çš„APIå¯†é’¥ä»¥ä½¿ç”¨æ‰€æœ‰åŠŸèƒ½ï¼š")
        
        # APIå¯†é’¥è¾“å…¥åŒºåŸŸ
        api_key = st.text_input(
            "APIå¯†é’¥",
            type="password",
            placeholder="è¯·è¾“å…¥æ‚¨çš„APIå¯†é’¥...",
            help="è¯·è¾“å…¥æ‚¨çš„APIå¯†é’¥ä»¥å¯ç”¨AIåŠŸèƒ½",
            key="api_key_input_prompt"
        )
        
        # è®¾ç½®æŒ‰é’®
        if st.button("âœ… è®¾ç½®å¯†é’¥", use_container_width=True, key="set_key_prompt"):
            if api_key:
                # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
                st.session_state.api_key_persistent = api_key
                st.session_state["api_key"] = api_key
                st.success("âœ… APIå¯†é’¥è®¾ç½®æˆåŠŸï¼")
                st.rerun()
            else:
                st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥")
    
    st.markdown("---")

def optimize_prompt(client, user_input, selected_model, conversation_history=None):
    """ä¼˜åŒ–æç¤ºè¯"""
    try:
        # æ„å»ºä¼˜åŒ–è¯·æ±‚
        model_specific_prompt = get_model_specific_prompt(selected_model)
        
        optimization_prompt = f"""
{model_specific_prompt}

ç”¨æˆ·éœ€æ±‚ï¼š
{user_input}

è¯·æ ¹æ®ç›®æ ‡å¤§æ¨¡å‹çš„ç‰¹ç‚¹ï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€é«˜æ•ˆçš„AIæç¤ºè¯ï¼Œè¦æ±‚ï¼š
1. æ¸…æ™°æ˜ç¡®çš„ç›®æ ‡å’Œè§’è‰²å®šä¹‰
2. å…·ä½“çš„ä»»åŠ¡æè¿°å’ŒæœŸæœ›è¾“å‡º
3. é€‚å½“çš„çº¦æŸå’ŒæŒ‡å¯¼åŸåˆ™
4. ä¸“ä¸šä¸”æ˜“äºç†è§£çš„è¡¨è¾¾
5. é’ˆå¯¹ç›®æ ‡å¤§æ¨¡å‹çš„ç‰¹ç‚¹è¿›è¡Œä¼˜åŒ–
6. è€ƒè™‘æ¨¡å‹çš„ä¼˜åŠ¿å’Œé€‚ç”¨åœºæ™¯

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„æç¤ºè¯ï¼Œæ— éœ€å…¶ä»–è¯´æ˜ã€‚
"""
        
        messages = [
            {"role": "system", "content": PROMPT_ENGINEER_SYSTEM_PROMPT}
        ]
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            for msg in conversation_history:
                messages.append({"role": msg["role"], "content": msg["content"]})
        
        # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
        messages.append({"role": "user", "content": optimization_prompt})
        
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            stream=False,
            temperature=0.3,
            max_tokens=1500
        )
        
        response = completion.choices[0].message.content
        return response.strip()
        
    except Exception as e:
        st.error(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
        return None

def continue_optimization(client, conversation_history, user_input, selected_model):
    """ç»§ç»­ä¼˜åŒ–æç¤ºè¯"""
    try:
        # æ„å»ºç»§ç»­ä¼˜åŒ–çš„è¯·æ±‚
        model_specific_prompt = get_model_specific_prompt(selected_model)
        
        messages = [
            {"role": "system", "content": PROMPT_ENGINEER_SYSTEM_PROMPT}
        ]
        
        # æ·»åŠ å¯¹è¯å†å²
        for msg in conversation_history:
            messages.append({"role": msg["role"], "content": msg["content"]})
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯å’Œç”¨æˆ·æ–°è¾“å…¥
        messages.append({"role": "user", "content": f"{model_specific_prompt}\n\nç”¨æˆ·åé¦ˆï¼š{user_input}"})
        
        completion = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            stream=False
        )
        
        return completion.choices[0].message.content
    except Exception as e:
        st.error(f"ç»§ç»­ä¼˜åŒ–å¤±è´¥: {e}")
        return None

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []
    
    if "debug_mode" not in st.session_state:
        st.session_state.debug_mode = False
    
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "GPT-4"

def reset_conversation():
    """é‡ç½®å¯¹è¯"""
    st.session_state.conversation_history = []
    st.rerun()

def display_conversation_history():
    """æ˜¾ç¤ºå¯¹è¯å†å²"""
    if st.session_state.conversation_history:
        st.markdown("### ğŸ’¬ å¯¹è¯å†å²")
        
        for i, message in enumerate(st.session_state.conversation_history):
            if message["role"] == "user":
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>ğŸ‘¤ ç”¨æˆ·:</strong><br>
                    {message["content"]}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message assistant-message">
                    <strong>ğŸ¤– åŠ©æ‰‹:</strong><br>
                    {message["content"]}
                </div>
                """, unsafe_allow_html=True)

def display_model_info(selected_model):
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    if selected_model in MODEL_CONFIGS:
        model_info = MODEL_CONFIGS[selected_model]
        st.markdown(f"""
        <div class="model-info">
            <strong>ğŸ“‹ æ¨¡å‹ä¿¡æ¯ï¼š{selected_model}</strong><br>
            <em>{model_info['description']}</em><br>
            <strong>ä¼˜åŠ¿ï¼š</strong>{', '.join(model_info['strengths'])}<br>
            <strong>é€‚ç”¨åœºæ™¯ï¼š</strong>{model_info['best_for']}
        </div>
        """, unsafe_allow_html=True)

def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()
    
    # åŠ è½½æŒä¹…åŒ–çš„APIå¯†é’¥
    if "api_key_persistent" in st.session_state:
        api_key = st.session_state.api_key_persistent
        if api_key and api_key != st.session_state.get("api_key"):
            st.session_state["api_key"] = api_key
    
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <h1 style="
            font-size: 2.5rem; 
            font-weight: bold; 
            color: #333;
            margin: 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        ">ğŸ”§ æç¤ºè¯å·¥ç¨‹å¸ˆ</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # APIå¯†é’¥è®¾ç½®åŒºåŸŸ
    setup_api_key()
    
    # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å·²è®¾ç½®
    if not check_api_key():
        # å¦‚æœAPIå¯†é’¥æœªè®¾ç½®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
        st.markdown("""
        <div style="text-align: center; padding: 2rem; background: rgba(255,255,255,0.1); border-radius: 15px; margin: 2rem 0;">
            <h3>ğŸ”‘ è¯·å…ˆè®¾ç½®APIå¯†é’¥</h3>
            <p>è®¾ç½®APIå¯†é’¥åå³å¯ä½¿ç”¨æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½</p>
        </div>
        """, unsafe_allow_html=True)
        return
    
    # è¿”å›é¦–é¡µæŒ‰é’®å’Œé‡ç½®å¯¹è¯æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        st.markdown("""
        <div style="text-align: center;">
            <a href="https://findknow-aitools.streamlit.app/" target="_blank" style="
                display: inline-block;
                background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 0.5rem 1.5rem;
                text-decoration: none;
                border-radius: 25px;
                font-weight: bold;
                width: 100%;
                text-align: center;
                box-sizing: border-box;
            ">ğŸ  è¿”å›é¦–é¡µ</a>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        if st.button("ğŸ”„ é‡ç½®å¯¹è¯", use_container_width=True, help="æ¸…ç©ºæ‰€æœ‰å¯¹è¯å†å²å¹¶é‡æ–°å¼€å§‹"):
            reset_conversation()
    with col3:
        st.write("")  # å ä½ç¬¦ï¼Œä¿æŒå¸ƒå±€å¹³è¡¡
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    display_conversation_history()
    
    # å¤§æ¨¡å‹é€‰æ‹©åŒºåŸŸ
    st.markdown("### ğŸ¤– é€‰æ‹©ç›®æ ‡å¤§æ¨¡å‹")
    st.markdown("è¯·é€‰æ‹©ä½ æƒ³è¦å°†æç¤ºè¯åº”ç”¨çš„å¤§æ¨¡å‹ï¼Œæˆ‘å°†æ ¹æ®æ¨¡å‹ç‰¹ç‚¹ä¸ºæ‚¨æä¾›é’ˆå¯¹æ€§çš„ä¼˜åŒ–å»ºè®®ã€‚")
    
    # æ¨¡å‹é€‰æ‹©å™¨
    selected_model = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹",
        options=list(MODEL_CONFIGS.keys()),
        index=list(MODEL_CONFIGS.keys()).index(st.session_state.selected_model),
        key="model_selector"
    )
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.selected_model = selected_model
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    display_model_info(selected_model)
    
    # æç¤ºä¿¡æ¯
    st.markdown("""
    <div class="card">
        <p class="placeholder-text">è¯·æè¿°æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘å°†æ ¹æ®é€‰æ‹©çš„å¤§æ¨¡å‹ä¸ºæ‚¨ä¼˜åŒ–æç¤ºè¯ï¼Œè®©AIæ›´å¥½åœ°ç†è§£æ‚¨çš„æ„å›¾...</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    st.markdown("### âœï¸ éœ€æ±‚æè¿°")
    user_input = st.text_area(
        "è¯·æè¿°æ‚¨çš„éœ€æ±‚æˆ–åé¦ˆ",
        height=150,
        placeholder="ä¾‹å¦‚ï¼šæˆ‘éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿåˆ†æè´¢åŠ¡æŠ¥è¡¨çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè¯†åˆ«å…³é”®æŒ‡æ ‡å¹¶æä¾›æŠ•èµ„å»ºè®®...",
        key="user_input_text"
    )
    
    # è°ƒè¯•é€‰é¡¹
    debug_mode = st.checkbox("ğŸ”§ è°ƒè¯•æ¨¡å¼", help="æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯", key="debug_mode")
    
    # æŒ‰é’®åŒºåŸŸ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        optimize_clicked = st.button("ğŸ”§ å¼€å§‹ä¼˜åŒ–", use_container_width=True)
    
    with col2:
        continue_clicked = st.button("ğŸ’¬ ç»§ç»­å¯¹è¯", use_container_width=True, disabled=not st.session_state.conversation_history)
    
    # å¤„ç†å¼€å§‹ä¼˜åŒ–
    if optimize_clicked:
        if not user_input:
            st.warning("è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚æè¿°ï¼")
            return
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        st.session_state.conversation_history.append({
            "role": "user",
            "content": f"ç›®æ ‡æ¨¡å‹ï¼š{selected_model}\n\néœ€æ±‚ï¼š{user_input}"
        })
        
        # å¼€å§‹ä¼˜åŒ–
        with st.spinner("æ­£åœ¨æ ¹æ®ç›®æ ‡æ¨¡å‹ä¼˜åŒ–æç¤ºè¯..."):
            client = init_client()
            if client:
                result = optimize_prompt(client, user_input, selected_model, st.session_state.conversation_history[:-1])
                
                if result:
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": result
                    })
                    
                    st.success("âœ… ä¼˜åŒ–å®Œæˆï¼")
                    st.rerun()
                else:
                    st.error("æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•")
    
    # å¤„ç†ç»§ç»­å¯¹è¯
    elif continue_clicked:
        if not user_input:
            st.warning("è¯·è¾“å…¥æ‚¨çš„åé¦ˆæˆ–é—®é¢˜ï¼")
            return
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        st.session_state.conversation_history.append({
            "role": "user",
            "content": user_input
        })
        
        # ç»§ç»­ä¼˜åŒ–
        with st.spinner("æ­£åœ¨å¤„ç†æ‚¨çš„åé¦ˆ..."):
            client = init_client()
            if client:
                result = continue_optimization(client, st.session_state.conversation_history[:-1], user_input, selected_model)
                
                if result:
                    # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å¯¹è¯å†å²
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": result
                    })
                    
                    st.success("âœ… å·²æ›´æ–°ä¼˜åŒ–ç»“æœï¼")
                    st.rerun()
                else:
                    st.error("å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•")
    


if __name__ == "__main__":
    main() 